{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bbf5ac6",
   "metadata": {},
   "source": [
    "# Spacy Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9290bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# loaded a language model and named it NLP\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660c5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Doc object\n",
    "# by applying model to text\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b61e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print each token separately\n",
    "for token in doc:\n",
    "    # raw text, part of speech, syntatic dependency\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "910176b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x7fea42065fd0>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x7fea29a47b30>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x7fea29a63110>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# breaks down\n",
    "nlp.pipeline\n",
    "# nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690427a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400b8ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj tesla\n",
      "is VERB aux be\n",
      "n't ADV neg not\n",
      "  SPACE   \n",
      "looking VERB ROOT look\n",
      "into ADP prep into\n",
      "startups NOUN pobj startup\n",
      "anymore ADV advmod anymore\n",
      ". PUNCT punct .\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"Tesla isn't  looking into startups anymore.\")\n",
    "\n",
    "# Print each token separately\n",
    "for token in doc2:\n",
    "    # raw text, part of speech, syntatic dependency\n",
    "    print(token.text, token.pos_, token.dep_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5390872",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "734cb3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Life is what happens to us while we are making other plans\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for idx, token in enumerate(doc3):\n",
    "#     print(idx, token.text)\n",
    "\n",
    "doc3[16:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4771ddb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Dr. Sean.\n",
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u'My name is Dr. Sean. This is the first sentence. This is another sentence. This is the last sentence.')\n",
    "\n",
    "for sent in doc4.sents:\n",
    "    print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8706d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188ea35b",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0854ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ade5795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystring = '\"We\\'re Moving to L.A.!\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0f00b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a296ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "We\n",
      "'re\n",
      "Moving\n",
      "to\n",
      "L.A.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "036f0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd15d9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "Send\n",
      "snail\n",
      "-\n",
      "mail\n",
      ",\n",
      "email\n",
      "support@oursite.com\n",
      "or\n",
      "visit\n",
      "us\n",
      "at\n",
      "http://www.oursite.com\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for t in doc2:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "343e2ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "NYC\n",
      "cab\n",
      "ride\n",
      "costs\n",
      "$\n",
      "10.30\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u'A 5km NYC cab ride costs $10.30')\n",
    "\n",
    "for t in doc3:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ec8a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "Louis\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u\"Let's visit St. Louis in the U.S. next year.\")\n",
    "\n",
    "for t in doc4:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b671482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5km NYC - QUANTITY - Measurements, as of weight or distance\n",
      "10.30 - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dc28961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "better to give"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5 = nlp(u'It is better to give than to receive.')\n",
    "\n",
    "# Retrieve the third token:\n",
    "doc5[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1139f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "than to receive."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the last four tokens:\n",
    "doc5[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "532b0780",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc05' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sy/_q8cxy317d5dbc3r358zm74m0000gn/T/ipykernel_3415/746771566.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc05\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'doc05' is not defined"
     ]
    }
   ],
   "source": [
    "doc05[0] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d14431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | \n",
      "----\n",
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "Hong Kong - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc8 = nlp(u'Apple to build a Hong Kong factory for $6 million')\n",
    "\n",
    "for token in doc8:\n",
    "    print(token.text, end=' | ')\n",
    "\n",
    "print('\\n----')\n",
    "\n",
    "for ent in doc8.ents:\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0ba714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5km NYC - QUANTITY - Measurements, as of weight or distance\n",
      "10.30 - MONEY - Monetary values, including unit\n",
      "\n",
      "---------------\n",
      "St. Louis - GPE - Countries, cities, states\n",
      "U.S. - GPE - Countries, cities, states\n",
      "next year - DATE - Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "for ent in doc3.ents:\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    \n",
    "    \n",
    "print('\\n'+15*'-')\n",
    "\n",
    "for ent in doc4.ents:\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04a06ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "insurance liability\n",
      "manufacturers\n"
     ]
    }
   ],
   "source": [
    "doc9 = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "\n",
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b7f5c",
   "metadata": {},
   "source": [
    "# Built-In Visualizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e541cb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1010\" height=\"297.0\" style=\"max-width: none; height: 297.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"130\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"130\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"210\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"210\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"370\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"370\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"690\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"690\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,162.0 C70,82.0 200.0,82.0 200.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,164.0 L62,152.0 78,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M150,162.0 C150,122.0 195.0,122.0 195.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M150,164.0 L142,152.0 158,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M310,162.0 C310,122.0 355.0,122.0 355.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M310,164.0 L302,152.0 318,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M230,162.0 C230,82.0 360.0,82.0 360.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M360.0,164.0 L368.0,152.0 352.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M470,162.0 C470,82.0 600.0,82.0 600.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M470,164.0 L462,152.0 478,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M550,162.0 C550,122.0 595.0,122.0 595.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550,164.0 L542,152.0 558,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M390,162.0 C390,42.0 605.0,42.0 605.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M605.0,164.0 L613.0,152.0 597.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M390,162.0 C390,2.0 690.0,2.0 690.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M690.0,164.0 L698.0,152.0 682.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M790,162.0 C790,82.0 920.0,82.0 920.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,164.0 L782,152.0 798,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-9\" stroke-width=\"2px\" d=\"M870,162.0 C870,122.0 915.0,122.0 915.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M870,164.0 L862,152.0 878,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-10\" stroke-width=\"2px\" d=\"M710,162.0 C710,42.0 925.0,42.0 925.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-10\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,164.0 L933.0,152.0 917.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 80})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f428d867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    iPods\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee33990",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9232df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the toolkit and the full Porter Stemmer library\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3222ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66b16592",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','running','ran','runs','easily','fairly', 'fairness','fairy','fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ceedc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run----->run\n",
      "runner----->runner\n",
      "running----->run\n",
      "ran----->ran\n",
      "runs----->run\n",
      "easily----->easili\n",
      "fairly----->fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '----->' + p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c050a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "572a053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f7a495ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run -----> run\n",
      "runner -----> runner\n",
      "running -----> run\n",
      "ran -----> ran\n",
      "runs -----> run\n",
      "easily -----> easili\n",
      "fairly -----> fair\n",
      "fairness -----> fair\n",
      "fairy -----> fairi\n",
      "fare -----> fare\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + ' -----> ' + s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ddf6c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous -----> generous\n",
      "generation -----> generat\n",
      "generated -----> generat\n",
      "gernerously -----> gerner\n",
      "generate -----> generat\n",
      "gene -----> gene\n",
      "generated -----> generat\n",
      "giving -----> give\n",
      "gave -----> gave\n"
     ]
    }
   ],
   "source": [
    "words = ['generous','generation','generated','gernerously','generate','gene','generated','giving','gave']\n",
    "for word in words:\n",
    "    print(word + ' -----> ' + s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8009fe",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1025dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cab2dafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t -PRON-\n",
      "am \t VERB \t be\n",
      "a \t DET \t a\n",
      "runner \t NOUN \t runner\n",
      "running \t VERB \t run\n",
      "in \t ADP \t in\n",
      "a \t DET \t a\n",
      "race \t NOUN \t race\n",
      "because \t ADP \t because\n",
      "I \t PRON \t -PRON-\n",
      "love \t VERB \t love\n",
      "to \t PART \t to\n",
      "run \t VERB \t run\n",
      "since \t ADP \t since\n",
      "I \t PRON \t -PRON-\n",
      "ran \t VERB \t run\n",
      "today \t NOUN \t today\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")\n",
    "\n",
    "for token in doc1:\n",
    "    print(token.text, '\\t', token.pos_, '\\t', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c65eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "545d4c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   561228191312463089     -PRON-\n",
      "saw          VERB   11925638236994514241   see\n",
      "eighteen     NUM    9609336664675087640    eighteen\n",
      "mice         NOUN   1384165645700560590    mouse\n",
      "today        NOUN   11042482332948150395   today\n",
      "!            PUNCT  17494803046312582752   !\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"I saw eighteen mice today!\")\n",
    "\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b6947c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   561228191312463089     -PRON-\n",
      "am           VERB   10382539506755952630   be\n",
      "meeting      VERB   6880656908171229526    meet\n",
      "him          PRON   561228191312463089     -PRON-\n",
      "tomorrow     NOUN   3573583789758258062    tomorrow\n",
      "at           ADP    11667289587015813222   at\n",
      "the          DET    7425985699627899538    the\n",
      "meeting      NOUN   14798207169164081740   meeting\n",
      ".            PUNCT  12646065887601541794   .\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u\"I am meeting him tomorrow at the meeting.\")\n",
    "\n",
    "show_lemmas(doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ef04a",
   "metadata": {},
   "source": [
    "\n",
    "# Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be24d028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and', 'whether', 'many', 'nor', 'such', 'three', 'yet', 'few', 'does', 'because', 'anything', 'either', 'us', 'between', 'although', 'against', 'other', 'eleven', 'thereupon', 'nevertheless', 'we', 'when', 'or', 'at', 'everyone', 'rather', 'anyone', 'seem', 'to', 'very', 'among', 'into', 'doing', 'done', 'take', 'now', 'unless', 'by', 'nine', 'yourselves', 'seeming', 'both', 'forty', 'name', 'part', 'also', 'were', 'beforehand', 'becomes', 'whither', 'down', 'him', 'may', 'enough', 'everything', 'already', 'none', 'noone', 'six', 'must', 'once', 'that', 'another', 'except', 'itself', 'always', 'toward', 'besides', 'really', 'in', 'seems', 'its', 'seemed', 'however', 'too', 'i', 'mostly', 'only', 'becoming', 'off', 'mine', 'show', 'see', 'serious', 'up', 'was', 'whose', 'you', 'per', 'along', 'therein', 'as', 'your', 'onto', 'for', 'from', 'than', 'out', 'using', 'behind', 'ours', 'still', 'until', 'who', 'anyway', 'somewhere', 'not', 'various', 'before', 'each', 'have', 'again', 'am', 'around', 'move', 'often', 'twelve', 'where', 'amongst', 'whom', 'amount', 'on', 'back', 'whoever', 'others', 'through', 'should', 'which', 'cannot', 'neither', 'themselves', 'moreover', 'all', 'no', 'how', 'ever', 'latterly', 're', 'somehow', 'one', 'former', 'has', 'after', 'several', 'every', 'whence', 'hereupon', 'whole', 'formerly', 'whereby', 'above', 'since', 'own', 'they', 'here', 'ten', 'over', 'the', 'anyhow', 'almost', 'front', 'hence', 'together', 'if', 'much', 'yours', 'our', 'hereby', 'his', 'latter', 'beyond', 'meanwhile', 'sometimes', 'why', 'empty', 'it', 'side', 'this', 'thru', 'while', 'do', 'last', 'been', 'otherwise', 'hers', 'himself', 'sixty', 'never', 'whereupon', 'during', 'across', 'then', 'whereafter', 'her', 'most', 'further', 'might', 'became', 'herself', 'even', 'he', 'what', 'could', 'five', 'ca', 'a', 'therefore', 'under', 'least', 'third', 'thence', 'any', 'eight', 'being', 'hundred', 'some', 'yourself', 'just', 'give', 'are', 'perhaps', 'those', 'will', 'please', 'within', 'less', 'there', 'elsewhere', 'fifteen', 'afterwards', 'thus', 'well', 'myself', 'two', 'via', 'regarding', 'more', 'keep', 'herein', 'wherein', 'with', 'these', 'wherever', 'beside', 'become', 'next', 'ourselves', 'twenty', 'but', 'indeed', 'nobody', 'of', 'did', 'upon', 'though', 'thereafter', 'four', 'bottom', 'same', 'whenever', 'them', 'alone', 'nothing', 'sometime', 'put', 'whereas', 'had', 'make', 'she', 'an', 'something', 'say', 'without', 'nowhere', 'namely', 'quite', 'fifty', 'else', 'is', 'whatever', 'everywhere', 'throughout', 'top', 'so', 'get', 'someone', 'be', 'can', 'go', 'their', 'thereby', 'about', 'hereafter', 'me', 'due', 'towards', 'anywhere', 'made', 'first', 'used', 'call', 'full', 'would', 'below', 'my'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Print the set of spaCy's default stop words (remember that sets are unordered):\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "34d54138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f7c7401f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'is' in nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5d490800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f885ee70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['myspace'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "117e50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the word to the set of stop words. Use lowercase!\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "\n",
    "# Set the stop_word tag on the lexeme\n",
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c95de35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the word from the set of stop words\n",
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "\n",
    "# Remove the stop_word tag from the lexeme\n",
    "nlp.vocab['beyond'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "48919d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'btw' in nlp.Defaults.stop_words, 'beyond' in nlp.Defaults.stop_words, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f525a63",
   "metadata": {},
   "source": [
    "# Vocabulary and Matching part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "106c7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "016447ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Redefine the patterns:\n",
    "# SolarPower\n",
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "# Solar-Power\n",
    "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}]\n",
    "# Solar Power\n",
    "# pattern3 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6cb5f0d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "8656102463236116519",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sy/_q8cxy317d5dbc3r358zm74m0000gn/T/ipykernel_3415/1968700632.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SolarPower'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmatcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.Matcher.remove\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 8656102463236116519"
     ]
    }
   ],
   "source": [
    "matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ac925713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new set of patterns to the 'SolarPower' matcher:\n",
    "# # OLD\n",
    "# matcher.add('SolarPower', None, pattern1, pattern2)\n",
    "matcher.add('SolarPower', None,  pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5cc85a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The Solar Power industry continues to grow as demand \\\n",
    "for solarpower increases. Solar-power cars are gaining popularity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f51abc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 10, 11), (8656102463236116519, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8822c0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 10 11 solarpower\n",
      "8656102463236116519 SolarPower 13 16 Solar-power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "    span = doc[start:end]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "54f70e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the patterns:\n",
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'power'}]\n",
    "\n",
    "# Remove the old patterns to avoid duplication:\n",
    "matcher.remove('SolarPower')\n",
    "\n",
    "# Add the new set of patterns to the 'SolarPower' matcher:\n",
    "matcher.add('SolarPower', None, pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e92b6404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 0, 3), (8656102463236116519, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"Solar--power is solarpower yay!\")\n",
    "found_matches = matcher(doc2)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7d623556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solar        ADJ    3825196732376443040    solar\n",
      "--           PUNCT  10501404726543969396   --\n",
      "power        NOUN   10405720708504167118   power\n",
      "is           VERB   10382539506755952630   be\n",
      "solarpower   NOUN   5703546853475899243    solarpower\n",
      "yay          NUM    17916626178616515936   yay\n",
      "!            PUNCT  17494803046312582752   !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c5a8c",
   "metadata": {},
   "source": [
    "# Vocabulary and Matching part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "75b42603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports, reset nlp\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "210bf247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../TextFiles/reaganomics.txt', encoding='utf-8') as f:\n",
    "\n",
    "# encoding='cp1252' is Windows text encoding\n",
    "with open('../TextFiles/reaganomics.txt', encoding='cp1252') as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c09d0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list = ['voodoo economics','supply-side economics','trickle-down economics','free-market economics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c0039c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[voodoo economics,\n",
       " supply-side economics,\n",
       " trickle-down economics,\n",
       " free-market economics]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "phrase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "28b7cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('EconMatcher',None,*phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1b762f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "41141bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680293220734633682 EconMatcher 41 45 policies are commonly associated with supply-side economics, referred to as trickle\n",
      "3680293220734633682 EconMatcher 49 53 economics, referred to as trickle-down economics or voodoo economics by political\n",
      "3680293220734633682 EconMatcher 54 56 trickle-down economics or voodoo economics by political opponents, and\n",
      "3680293220734633682 EconMatcher 61 65 by political opponents, and free-market economics by political advocates.\n",
      "\n",
      "\n",
      "3680293220734633682 EconMatcher 673 677 attracted a following from the supply-side economics movement, which formed in\n",
      "3680293220734633682 EconMatcher 2985 2989 became widely known as \"trickle-down economics\", due to the\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "    span = doc3[start-5:end+5]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdba134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62536b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
