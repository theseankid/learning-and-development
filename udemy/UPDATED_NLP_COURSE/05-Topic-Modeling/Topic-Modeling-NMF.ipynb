{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "For DTM Matrix $A$ find matrices $W,H$ such that of rank $k$ (selected ahead of time)\n",
    "\n",
    "$$ A \\sim W \\cdot H$$\n",
    "\n",
    "where $W$ is basis vectors, and $H$ is coefficients of memeberships for documents\n",
    "\n",
    "## Process\n",
    "\n",
    "1. find TF-IDF matrix $A$ (DTM) via construction of vector space model for documents (after removing stopwords)\n",
    "2. apply TF-IDF term weight normalization to matrix $A$\n",
    "3. Normalize TF-IDF vectors\n",
    "4. initialize factors using NNDSVD (Non-Negative Double Singular Value Decomposition) on $A$ \n",
    "5. apply projected gradient NMF to $A$\n",
    "\n",
    "## Result\n",
    "\n",
    "* Basis Vectors: topics (clusters) in the data\n",
    "* Coefficiant Matrix: membership weights for documents relative to each topic (cluster)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = pd.read_csv('npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11992 entries, 0 to 11991\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Article  11992 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 93.8+ KB\n"
     ]
    }
   ],
   "source": [
    "npr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not actually a dtm matrix, just writing to line up with previous code\n",
    "dtm = tfidf.fit_transform(npr['Article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NMF in module sklearn.decomposition._nmf:\n",
      "\n",
      "class NMF(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  NMF(n_components=None, *, init='warn', solver='cd', beta_loss='frobenius', tol=0.0001, max_iter=200, random_state=None, alpha='deprecated', alpha_W=0.0, alpha_H='same', l1_ratio=0.0, verbose=0, shuffle=False, regularization='deprecated')\n",
      " |  \n",
      " |  Non-Negative Matrix Factorization (NMF).\n",
      " |  \n",
      " |  Find two non-negative matrices (W, H) whose product approximates the non-\n",
      " |  negative matrix X. This factorization can be used for example for\n",
      " |  dimensionality reduction, source separation or topic extraction.\n",
      " |  \n",
      " |  The objective function is:\n",
      " |  \n",
      " |      .. math::\n",
      " |  \n",
      " |          0.5 * ||X - WH||_{loss}^2\n",
      " |  \n",
      " |          + alpha\\_W * l1_{ratio} * n\\_features * ||vec(W)||_1\n",
      " |  \n",
      " |          + alpha\\_H * l1_{ratio} * n\\_samples * ||vec(H)||_1\n",
      " |  \n",
      " |          + 0.5 * alpha\\_W * (1 - l1_{ratio}) * n\\_features * ||W||_{Fro}^2\n",
      " |  \n",
      " |          + 0.5 * alpha\\_H * (1 - l1_{ratio}) * n\\_samples * ||H||_{Fro}^2\n",
      " |  \n",
      " |  Where:\n",
      " |  \n",
      " |  :math:`||A||_{Fro}^2 = \\sum_{i,j} A_{ij}^2` (Frobenius norm)\n",
      " |  \n",
      " |  :math:`||vec(A)||_1 = \\sum_{i,j} abs(A_{ij})` (Elementwise L1 norm)\n",
      " |  \n",
      " |  The generic norm :math:`||X - WH||_{loss}` may represent\n",
      " |  the Frobenius norm or another supported beta-divergence loss.\n",
      " |  The choice between options is controlled by the `beta_loss` parameter.\n",
      " |  \n",
      " |  The regularization terms are scaled by `n_features` for `W` and by `n_samples` for\n",
      " |  `H` to keep their impact balanced with respect to one another and to the data fit\n",
      " |  term as independent as possible of the size `n_samples` of the training set.\n",
      " |  \n",
      " |  The objective function is minimized with an alternating minimization of W\n",
      " |  and H.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <NMF>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_components : int, default=None\n",
      " |      Number of components, if n_components is not set all features\n",
      " |      are kept.\n",
      " |  \n",
      " |  init : {'random', 'nndsvd', 'nndsvda', 'nndsvdar', 'custom'}, default=None\n",
      " |      Method used to initialize the procedure.\n",
      " |      Default: None.\n",
      " |      Valid options:\n",
      " |  \n",
      " |      - `None`: 'nndsvd' if n_components <= min(n_samples, n_features),\n",
      " |        otherwise random.\n",
      " |  \n",
      " |      - `'random'`: non-negative random matrices, scaled with:\n",
      " |        sqrt(X.mean() / n_components)\n",
      " |  \n",
      " |      - `'nndsvd'`: Nonnegative Double Singular Value Decomposition (NNDSVD)\n",
      " |        initialization (better for sparseness)\n",
      " |  \n",
      " |      - `'nndsvda'`: NNDSVD with zeros filled with the average of X\n",
      " |        (better when sparsity is not desired)\n",
      " |  \n",
      " |      - `'nndsvdar'` NNDSVD with zeros filled with small random values\n",
      " |        (generally faster, less accurate alternative to NNDSVDa\n",
      " |        for when sparsity is not desired)\n",
      " |  \n",
      " |      - `'custom'`: use custom matrices W and H\n",
      " |  \n",
      " |  solver : {'cd', 'mu'}, default='cd'\n",
      " |      Numerical solver to use:\n",
      " |      'cd' is a Coordinate Descent solver.\n",
      " |      'mu' is a Multiplicative Update solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Coordinate Descent solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         Multiplicative Update solver.\n",
      " |  \n",
      " |  beta_loss : float or {'frobenius', 'kullback-leibler',             'itakura-saito'}, default='frobenius'\n",
      " |      Beta divergence to be minimized, measuring the distance between X\n",
      " |      and the dot product WH. Note that values different from 'frobenius'\n",
      " |      (or 2) and 'kullback-leibler' (or 1) lead to significantly slower\n",
      " |      fits. Note that for beta_loss <= 0 (or 'itakura-saito'), the input\n",
      " |      matrix X cannot contain zeros. Used only in 'mu' solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance of the stopping condition.\n",
      " |  \n",
      " |  max_iter : int, default=200\n",
      " |      Maximum number of iterations before timing out.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Used for initialisation (when ``init`` == 'nndsvdar' or\n",
      " |      'random'), and in Coordinate Descent. Pass an int for reproducible\n",
      " |      results across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  alpha : float, default=0.0\n",
      " |      Constant that multiplies the regularization terms. Set it to zero to\n",
      " |      have no regularization. When using `alpha` instead of `alpha_W` and `alpha_H`,\n",
      " |      the regularization terms are not scaled by the `n_features` (resp. `n_samples`)\n",
      " |      factors for `W` (resp. `H`).\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *alpha* used in the Coordinate Descent solver.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          The `alpha` parameter is deprecated in 1.0 and will be removed in 1.2.\n",
      " |          Use `alpha_W` and `alpha_H` instead.\n",
      " |  \n",
      " |  alpha_W : float, default=0.0\n",
      " |      Constant that multiplies the regularization terms of `W`. Set it to zero\n",
      " |      (default) to have no regularization on `W`.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  alpha_H : float or \"same\", default=\"same\"\n",
      " |      Constant that multiplies the regularization terms of `H`. Set it to zero to\n",
      " |      have no regularization on `H`. If \"same\" (default), it takes the same value as\n",
      " |      `alpha_W`.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  l1_ratio : float, default=0.0\n",
      " |      The regularization mixing parameter, with 0 <= l1_ratio <= 1.\n",
      " |      For l1_ratio = 0 the penalty is an elementwise L2 penalty\n",
      " |      (aka Frobenius Norm).\n",
      " |      For l1_ratio = 1 it is an elementwise L1 penalty.\n",
      " |      For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Regularization parameter *l1_ratio* used in the Coordinate Descent\n",
      " |         solver.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Whether to be verbose.\n",
      " |  \n",
      " |  shuffle : bool, default=False\n",
      " |      If true, randomize the order of coordinates in the CD solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *shuffle* parameter used in the Coordinate Descent solver.\n",
      " |  \n",
      " |  regularization : {'both', 'components', 'transformation', None},                      default='both'\n",
      " |      Select whether the regularization affects the components (H), the\n",
      " |      transformation (W), both or none of them.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          The `regularization` parameter is deprecated in 1.0 and will be removed in\n",
      " |          1.2. Use `alpha_W` and `alpha_H` instead.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  components_ : ndarray of shape (n_components, n_features)\n",
      " |      Factorization matrix, sometimes called 'dictionary'.\n",
      " |  \n",
      " |  n_components_ : int\n",
      " |      The number of components. It is same as the `n_components` parameter\n",
      " |      if it was given. Otherwise, it will be same as the number of\n",
      " |      features.\n",
      " |  \n",
      " |  reconstruction_err_ : float\n",
      " |      Frobenius norm of the matrix difference, or beta-divergence, between\n",
      " |      the training data ``X`` and the reconstructed data ``WH`` from\n",
      " |      the fitted model.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Actual number of iterations.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DictionaryLearning : Find a dictionary that sparsely encodes data.\n",
      " |  MiniBatchSparsePCA : Mini-batch Sparse Principal Components Analysis.\n",
      " |  PCA : Principal component analysis.\n",
      " |  SparseCoder : Find a sparse representation of data from a fixed,\n",
      " |      precomputed dictionary.\n",
      " |  SparsePCA : Sparse Principal Components Analysis.\n",
      " |  TruncatedSVD : Dimensionality reduction using truncated SVD.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Cichocki, Andrzej, and P. H. A. N. Anh-Huy. \"Fast local algorithms for\n",
      " |  large scale nonnegative matrix and tensor factorizations.\"\n",
      " |  IEICE transactions on fundamentals of electronics, communications and\n",
      " |  computer sciences 92.3: 708-721, 2009.\n",
      " |  \n",
      " |  Fevotte, C., & Idier, J. (2011). Algorithms for nonnegative matrix\n",
      " |  factorization with the beta-divergence. Neural Computation, 23(9).\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n",
      " |  >>> from sklearn.decomposition import NMF\n",
      " |  >>> model = NMF(n_components=2, init='random', random_state=0)\n",
      " |  >>> W = model.fit_transform(X)\n",
      " |  >>> H = model.components_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NMF\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_components=None, *, init='warn', solver='cd', beta_loss='frobenius', tol=0.0001, max_iter=200, random_state=None, alpha='deprecated', alpha_W=0.0, alpha_H='same', l1_ratio=0.0, verbose=0, shuffle=False, regularization='deprecated')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Learn a NMF model for the data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          Not used, present for API consistency by convention.\n",
      " |      \n",
      " |      **params : kwargs\n",
      " |          Parameters (keyword arguments) and values passed to\n",
      " |          the fit_transform instance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns the instance itself.\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, W=None, H=None)\n",
      " |      Learn a NMF model for the data X and returns the transformed data.\n",
      " |      \n",
      " |      This is more efficient than calling fit followed by transform.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          Not used, present for API consistency by convention.\n",
      " |      \n",
      " |      W : array-like of shape (n_samples, n_components)\n",
      " |          If init='custom', it is used as initial guess for the solution.\n",
      " |      \n",
      " |      H : array-like of shape (n_components, n_features)\n",
      " |          If init='custom', it is used as initial guess for the solution.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      W : ndarray of shape (n_samples, n_components)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  inverse_transform(self, W)\n",
      " |      Transform data back to its original space.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      W : {ndarray, sparse matrix} of shape (n_samples, n_components)\n",
      " |          Transformed data matrix.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Returns a data matrix of the original shape.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform the data X according to the fitted NMF model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      W : ndarray of shape (n_samples, n_components)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=7,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(n_components=7, random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'albala'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()[2300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 15 words for each topic\n",
      "\n",
      "\n",
      "TOPIC # 0:\n",
      "['new', 'research', 'like', 'patients', 'health', 'disease', 'percent', 'women', 'virus', 'study', 'water', 'food', 'people', 'zika', 'says']\n",
      "\n",
      "\n",
      "TOPIC # 1:\n",
      "['gop', 'pence', 'presidential', 'russia', 'administration', 'election', 'republican', 'obama', 'white', 'house', 'donald', 'campaign', 'said', 'president', 'trump']\n",
      "\n",
      "\n",
      "TOPIC # 2:\n",
      "['senate', 'house', 'people', 'act', 'law', 'tax', 'plan', 'republicans', 'affordable', 'obamacare', 'coverage', 'medicaid', 'insurance', 'care', 'health']\n",
      "\n",
      "\n",
      "TOPIC # 3:\n",
      "['officers', 'syria', 'security', 'department', 'law', 'isis', 'russia', 'government', 'state', 'attack', 'president', 'reports', 'court', 'said', 'police']\n",
      "\n",
      "\n",
      "TOPIC # 4:\n",
      "['primary', 'cruz', 'election', 'democrats', 'percent', 'party', 'delegates', 'vote', 'state', 'democratic', 'hillary', 'campaign', 'voters', 'sanders', 'clinton']\n",
      "\n",
      "\n",
      "TOPIC # 5:\n",
      "['love', 've', 'don', 'album', 'way', 'time', 'song', 'life', 'really', 'know', 'people', 'think', 'just', 'music', 'like']\n",
      "\n",
      "\n",
      "TOPIC # 6:\n",
      "['teacher', 'state', 'high', 'says', 'parents', 'devos', 'children', 'college', 'kids', 'teachers', 'student', 'education', 'schools', 'school', 'students']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = 15\n",
    "print(f'TOP {m} words for each topic\\n\\n')\n",
    "for idx, topic in enumerate(nmf_model.components_):\n",
    "    print(f'TOPIC # {idx}:')\n",
    "    print([tfidf.get_feature_names()[index] for index in topic.argsort()[-m:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = nmf_model.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.  , 0.12, 0.  , 0.06, 0.02, 0.  , 0.  ]), 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[0].round(2), topic_results[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr['topic'] = topic_results.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I did not want to join yoga class. I hated tho...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>With a   who has publicly supported the debunk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was standing by the airport exit, debating w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If movies were trying to be more realistic, pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Eighteen years ago, on New Year’s Eve, David F...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>For years now, some of the best, wildest, most...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>For years now, some of the best, wildest, most...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Colorado River is like a giant bank accoun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>For the last installment of NPR’s holiday reci...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Being overweight can raise your blood pressure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Who’s the YouTube star of 2016? Adele singing ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Here’s a quick roundup of some of the   you ma...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ben Johnston doesn’t follow the rules of music...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>David Bowie, Prince and George Michael are all...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In November, the typically straitlaced Office ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Article  topic\n",
       "0   In the Washington of 2016, even when the polic...      1\n",
       "1     Donald Trump has used Twitter  —   his prefe...      1\n",
       "2     Donald Trump is unabashedly praising Russian...      1\n",
       "3   Updated at 2:50 p. m. ET, Russian President Vl...      3\n",
       "4   From photography, illustration and video, to d...      6\n",
       "5   I did not want to join yoga class. I hated tho...      5\n",
       "6   With a   who has publicly supported the debunk...      0\n",
       "7   I was standing by the airport exit, debating w...      0\n",
       "8   If movies were trying to be more realistic, pe...      0\n",
       "9   Eighteen years ago, on New Year’s Eve, David F...      5\n",
       "10  For years now, some of the best, wildest, most...      5\n",
       "11  For years now, some of the best, wildest, most...      5\n",
       "12  The Colorado River is like a giant bank accoun...      0\n",
       "13  For the last installment of NPR’s holiday reci...      5\n",
       "14  Being overweight can raise your blood pressure...      0\n",
       "15  Who’s the YouTube star of 2016? Adele singing ...      5\n",
       "16  Here’s a quick roundup of some of the   you ma...      3\n",
       "17  Ben Johnston doesn’t follow the rules of music...      5\n",
       "18  David Bowie, Prince and George Michael are all...      5\n",
       "19  In November, the typically straitlaced Office ...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_topic_dictionary = {\n",
    "    6:'education',\n",
    "    5:'lifestyle',\n",
    "    4:'elections',\n",
    "    3:'geopolitics',\n",
    "    2:'legislation',\n",
    "    1:'election',\n",
    "    0:'public health'\n",
    "}\n",
    "\n",
    "\n",
    "npr['topic_label'] = npr['topic'].map(my_topic_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>3</td>\n",
       "      <td>geopolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>6</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I did not want to join yoga class. I hated tho...</td>\n",
       "      <td>5</td>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>With a   who has publicly supported the debunk...</td>\n",
       "      <td>0</td>\n",
       "      <td>public health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was standing by the airport exit, debating w...</td>\n",
       "      <td>0</td>\n",
       "      <td>public health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If movies were trying to be more realistic, pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>public health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Eighteen years ago, on New Year’s Eve, David F...</td>\n",
       "      <td>5</td>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>For years now, some of the best, wildest, most...</td>\n",
       "      <td>5</td>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>For years now, some of the best, wildest, most...</td>\n",
       "      <td>5</td>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Colorado River is like a giant bank accoun...</td>\n",
       "      <td>0</td>\n",
       "      <td>public health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>For the last installment of NPR’s holiday reci...</td>\n",
       "      <td>5</td>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Being overweight can raise your blood pressure...</td>\n",
       "      <td>0</td>\n",
       "      <td>public health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Who’s the YouTube star of 2016? Adele singing ...</td>\n",
       "      <td>5</td>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Here’s a quick roundup of some of the   you ma...</td>\n",
       "      <td>3</td>\n",
       "      <td>geopolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ben Johnston doesn’t follow the rules of music...</td>\n",
       "      <td>5</td>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>David Bowie, Prince and George Michael are all...</td>\n",
       "      <td>5</td>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In November, the typically straitlaced Office ...</td>\n",
       "      <td>1</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Article  topic    topic_label\n",
       "0   In the Washington of 2016, even when the polic...      1       election\n",
       "1     Donald Trump has used Twitter  —   his prefe...      1       election\n",
       "2     Donald Trump is unabashedly praising Russian...      1       election\n",
       "3   Updated at 2:50 p. m. ET, Russian President Vl...      3    geopolitics\n",
       "4   From photography, illustration and video, to d...      6      education\n",
       "5   I did not want to join yoga class. I hated tho...      5      lifestyle\n",
       "6   With a   who has publicly supported the debunk...      0  public health\n",
       "7   I was standing by the airport exit, debating w...      0  public health\n",
       "8   If movies were trying to be more realistic, pe...      0  public health\n",
       "9   Eighteen years ago, on New Year’s Eve, David F...      5      lifestyle\n",
       "10  For years now, some of the best, wildest, most...      5      lifestyle\n",
       "11  For years now, some of the best, wildest, most...      5      lifestyle\n",
       "12  The Colorado River is like a giant bank accoun...      0  public health\n",
       "13  For the last installment of NPR’s holiday reci...      5      lifestyle\n",
       "14  Being overweight can raise your blood pressure...      0  public health\n",
       "15  Who’s the YouTube star of 2016? Adele singing ...      5      lifestyle\n",
       "16  Here’s a quick roundup of some of the   you ma...      3    geopolitics\n",
       "17  Ben Johnston doesn’t follow the rules of music...      5      lifestyle\n",
       "18  David Bowie, Prince and George Michael are all...      5      lifestyle\n",
       "19  In November, the typically straitlaced Office ...      1       election"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
